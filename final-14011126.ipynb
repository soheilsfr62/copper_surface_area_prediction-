{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.impute import IterativeImputer,SimpleImputer\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor , BaggingRegressor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, ShuffleSplit,StratifiedShuffleSplit, validation_curve, learning_curve, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor,MLPClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import ExtraTreeRegressor,ExtraTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('C:/Users/ASUS/Desktop/desk/ml/final1.xlsx',sheet_name='test1-CuZn.atm.NoInfinit-cf')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('C:/Users/ASUS/Desktop/desk/ml/final1.xlsx',sheet_name='test1-CuZn.atm.NoInfinit-f')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Generate a mask for the upper triangle; True = do NOT show\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "# More details at https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "sns.heatmap(\n",
    "    corr,          # The data to plot\n",
    "    mask=mask,     # Mask some cells\n",
    "    cmap=cmap,     # What colors to plot the heatmap as\n",
    "    annot=True,    # Should the values be plotted in the cells?\n",
    "    vmax=.3,       # The maximum value of the legend. All higher vals will be same color\n",
    "    vmin=-.3,      # The minimum value of the legend. All lower vals will be same color\n",
    "    center=0,      # The center value of the legend. With divergent cmap, where white is\n",
    "    square=True,   # Force cells to be square\n",
    "    linewidths=.5, # Width of lines that divide cells\n",
    "    cbar_kws={\"shrink\": .5}# Extra kwargs for the legend; in this case, shrink by 50%\n",
    ")\n",
    "\n",
    "# You can save this as a png with\n",
    "\n",
    "f.savefig('Desktop/heatmap_colored_correlation.jpeg', dpi=3000, bbox_inches='tight') #C:\\Users\\ASUS\\Desktop\\desk\\ml\\1401.07.10\\pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data).to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder=OrdinalEncoder()\n",
    "data[:,2:4]=encoder.fit_transform(data[:,2:4])\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[:,8:9] \n",
    "X=data[:,:8]\n",
    "#y=y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(y)):\n",
    "    if y[i,0]< 15:\n",
    "         y[i,0] = 0\n",
    "    elif 15 <=y[i,0]< 40:\n",
    "        y[i,0] = 1\n",
    "    else:\n",
    "        y[i,0] = 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y)\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "data= np.concatenate((X_train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[:,:-1]\n",
    "y= data[:,-1]\n",
    "y=pd.DataFrame(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "#data= np.concatenate((X,y), axis=1)\n",
    "from sklearn.utils import resample\n",
    "data_0 = data[data[:,-1]==0]\n",
    "data_1 = data[data[:,-1]==1]\n",
    "data_2 = data[data[:,-1]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "data_0_resampled= resample(data_0, n_samples= 72, random_state=23)\n",
    "data_2_resampled= resample(data_2, n_samples= 72, random_state=23)\n",
    "data_0_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "data= np.concatenate((data_0_resampled, data_1, data_2_resampled), axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(data).to_excel('Desktop/data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "X= data[:,:-1]\n",
    "y= data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "y= encoder.fit_transform(y.reshape(-1,1))\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= encoder.fit_transform(y_test.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_=pd.DataFrame(y_test)\n",
    "y_test_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y).to_numpy()\n",
    "y=y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "Scaler=StandardScaler()\n",
    "Scaler.fit(X)\n",
    "X_standard=Scaler.transform(X)\n",
    "joblib.dump(Scaler, 'scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "cv= StratifiedShuffleSplit(random_state=23, test_size=0.1)\n",
    "gscv= GridSearchCV(RandomForestClassifier(random_state=23), cv=cv, n_jobs=-1, param_grid={'n_estimators': np.arange(10,200,10)})\n",
    "gscv.fit(X_standard,y)\n",
    "print('best_score= ', gscv.best_score_)\n",
    "print('best_params= ', gscv.best_params_)\n",
    "print('best_test= ', gscv.best_estimator_.fit(X_standard,y).score(Scaler.transform(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in range (100):\n",
    "    \n",
    "#    from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split\n",
    "#    cv= StratifiedShuffleSplit(random_state=23, test_size=0.1)\n",
    "#    gscv= GridSearchCV(RandomForestClassifier(random_state=k), cv=cv, n_jobs=-1, param_grid={'n_estimators': [30]})\n",
    "#    gscv.fit(X_standard,y)\n",
    "#    print(k,'best_score= ', gscv.best_score_)\n",
    "#    print('best_params= ', gscv.best_params_)\n",
    "#    print('best_test= ', gscv.best_estimator_.fit(X_standard,y).score(Scaler.transform(X_test),y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples= np.arange(30,216,5)\n",
    "scores=[]\n",
    "for i in n_samples:\n",
    "    X_train_= X_standard[:i]\n",
    "    y_train_= y[:i]\n",
    "    gscv.best_estimator_.fit(X_train_,y_train_)\n",
    "    score= gscv.best_estimator_.score(Scaler.transform(X_test),y_test)\n",
    "    scores.append(score)\n",
    "plt.plot(n_samples, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "cv= StratifiedShuffleSplit(random_state=23, test_size=0.1)\n",
    "gscv= GridSearchCV(RandomForestClassifier(random_state=78), cv=cv, n_jobs=-1, param_grid={'n_estimators': [30]})\n",
    "gscv.fit(X_standard,y)\n",
    "print('best_score= ', gscv.best_score_)\n",
    "print('best_params= ', gscv.best_params_)\n",
    "print('best_test= ', gscv.best_estimator_.fit(X_standard,y).score(Scaler.transform(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "joblib.dump(gscv.best_estimator_, 'rf.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gscv.best_estimator_.predict(Scaler.transform(X_test))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test).to_numpy()\n",
    "y_test=y_test.ravel()\n",
    "y_true= y_test\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_Saeidi\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "rf= RandomForestClassifier(random_state=23)\n",
    "rf.fit(X_standard,y)\n",
    "print(rf.feature_importances_)\n",
    "print(mutual_info_classif(X_standard,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SenSitivity\n",
    "from sklearn.feature_selection import RFE\n",
    "selector= RFE(rf)\n",
    "selector.fit(X_standard,y)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score: %.2f'% accuracy_score(y_true, y_pred, normalize=True))\n",
    "print('precision_score: %.2f'%precision_score(y_true, y_pred,average='weighted'))\n",
    "print('recall_score: %.2f'% recall_score(y_true, y_pred,average='weighted'))\n",
    "target_names = ['Low', 'Medium', 'High']\n",
    "print(classification_report(y_true, y_pred), 'target_names'== target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['Low', 'Medium','High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colormaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "print('accuracy_score: %.2f'% accuracy_score(y_true, y_pred, normalize=True))\n",
    "print('precision_score: %.2f'%precision_score(y_true, y_pred,average='weighted'))\n",
    "print('recall_score: %.2f'% recall_score(y_true, y_pred,average='weighted'))\n",
    "confusion_matrix=confusion_matrix(y_true, y_pred)\n",
    "#labels = np.array(['low', 'medium','high'])\n",
    "#display_labels=clf.classes_\n",
    "#disp=ConfusionMatrixDisplay(confusion_matrix, display_labels=model.classes_)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix, display_labels=labels)\n",
    "\n",
    "fig=disp.plot(cmap='cividis')\n",
    "plt.savefig('Desktop/confusion matrix.jpeg', dpi=5000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=disp.plot(cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Cu/Zn','Al%','Precipitant','pH mode','Aging temperature (°C)','Aging time (h)','Calcination temperature (°C)','Calcination time (h)']\n",
    "class_names = ['Low','Medium','High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard=pd.DataFrame(X_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= joblib.load('rf.sav')\n",
    "explainer = shap.Explainer(rf)\n",
    "shap_values = explainer.shap_values(X_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=shap.summary_plot(shap_values, X_standard.values, plot_type=\"bar\", class_names= class_names, feature_names = feature_names, show=False)\n",
    "plt.savefig('Desktop/feature-importance.jpeg', dpi=4200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=shap.summary_plot(shap_values [0], X_standard.values, feature_names = feature_names, show=False, )\n",
    "plt.savefig('Desktop/shap-sum-plot-class-low.jpeg', dpi=3700, bbox_inches='tight') #max_display=14  #bbox_inches='tight', pad_inches=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values [1], X_standard.values, feature_names = feature_names, show=False)\n",
    "plt.savefig('Desktop/shap-sum-plot-class-medium.jpeg', dpi=3700, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values [2], X_standard.values, feature_names = feature_names, show=False)\n",
    "plt.savefig('Desktop/shap-sum-plot-class-high.jpeg', dpi=3700, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    shap.dependence_plot(i,shap_values[0], X_standard.values, feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    shap.dependence_plot(i,shap_values[1], X_standard.values, feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    shap.dependence_plot(i,shap_values[2], X_standard.values, feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "rf= joblib.load('rf.sav')\n",
    "\n",
    "cv= StratifiedShuffleSplit(n_splits=10, random_state=1)\n",
    "train_sizes, train_scores, test_scores= learning_curve(rf, X_standard, y, cv=cv, scoring='accuracy',\n",
    "                                                       n_jobs=-1, train_sizes=np.linspace(0.1, 1, 50))\n",
    "train_mean_scores=np.mean(train_scores, axis=1)\n",
    "test_mean_scores=np.mean(test_scores, axis=1)\n",
    "train_std= np.std(train_scores, axis=1)\n",
    "test_std= np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(X_standard).to_excel('Desktop/X_standard.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, train_mean_scores, label='Training score')\n",
    "plt.plot(train_sizes, test_mean_scores, label= 'Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean_scores-train_std, train_mean_scores+train_std, color = '#DDDDDD')\n",
    "plt.fill_between(train_sizes, test_mean_scores-test_std, test_mean_scores+test_std, color = '#DDDDDD')\n",
    "\n",
    "\n",
    "#plt.title('Learning Curve')\n",
    "plt.xlabel('Training size' ,fontweight=\"bold\")\n",
    "plt.ylabel('Accuracy score',fontweight=\"bold\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig('Desktop/learning-curve.jpeg', dpi=5000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
